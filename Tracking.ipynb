{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import glob\n",
    "import torch\n",
    "from classification import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update(x, P, Z, H, R):\n",
    "    ### Insert update function\n",
    "    Y = Z - np.dot(H,x)\n",
    "    S = np.dot(np.dot(H, P), np.transpose(H)) + R\n",
    "    K = np.dot(np.dot(P, np.transpose(H)), np.linalg.pinv(S))\n",
    "    X_prime = x + np.dot(K, Y)\n",
    "    P_prime = np.dot((I - np.dot(K, H)), P)\n",
    "    \n",
    "    return Y, S, K, X_prime, P_prime\n",
    "    \n",
    "def predict(x, P, F, u):\n",
    "    ### insert predict function\n",
    "    X_prime = np.dot(F,x) + u\n",
    "    P_prime = np.dot(np.dot(F, P), np.transpose(F))\n",
    "    \n",
    "    return X_prime, P_prime\n",
    "    \n",
    "    \n",
    "### Initialize Kalman filter ###\n",
    "# The initial state (6x1).\n",
    "x = np.array([[0], # Position along the x-axis\n",
    "              [0], # Velocity along the x-axis\n",
    "              [0], # Position along the y-axis\n",
    "              [0], # Velocity along the y-axis\n",
    "              [0], # Position along the z-axis\n",
    "              [0]])# Velocity along the z-axis\n",
    "\n",
    "# The initial uncertainty (6x6).\n",
    "P = np.array([[1000, 0, 0, 0, 0, 0],\n",
    "              [0, 1000, 0, 0, 0, 0],\n",
    "              [0, 0, 1000, 0, 0, 0],\n",
    "              [0, 0, 0, 1000, 0, 0],\n",
    "              [0, 0, 0, 0, 1000, 0],\n",
    "              [0, 0, 0, 0, 0, 1000]])\n",
    "\n",
    "# The external motion (6x1).\n",
    "u = np.array([[0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [0]])\n",
    "\n",
    "# The transition matrix (6x6).  \n",
    "F = np.array([[1, 1, 0, 0, 0, 0],\n",
    "              [0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 0, 0],\n",
    "              [0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 0, 1, 1],\n",
    "              [0, 0, 0 ,0, 0, 1]])\n",
    "\n",
    "# The observation matrix (2x6).\n",
    "H = np.array([[1, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 1, 0]])\n",
    "\n",
    "# The measurement uncertainty.\n",
    "R = 1\n",
    "              \n",
    "# The identity matrix. Simply a matrix with 1 in the diagonal and 0 elsewhere.\n",
    "I = np.array([[1, 0, 0, 0, 0, 0],\n",
    "              [0, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 0, 0, 0],\n",
    "              [0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 0, 1, 0],\n",
    "              [0, 0, 0, 0, 0, 1]])\n",
    "\n",
    "\n",
    "\n",
    "# Load the video\n",
    "images_left = sorted(glob.glob('../final_project_2023_rect/seq_01/image_02/data/*.png'))\n",
    "images_right = sorted(glob.glob('../final_project_2023_rect/seq_01/image_03/data/*.png'))\n",
    "assert images_left\n",
    "assert images_right\n",
    "for i in range(0,len(images_left)):\n",
    "    frame= cv2.imread(images_left[i])\n",
    "    frame = imutils.resize(frame, width=600)    \n",
    "    ### Detect the ball ### focal length (fx, fy) and optical centers (cx, cy)\n",
    "    # K_02 = [[fx 0 cx],\n",
    "      #      [0 fy cy],\n",
    "      #      [0 0 1]]\n",
    "    ## get focal length f from the K matrix\n",
    "    # focal_length = K_02[0][0]\n",
    "    ## compute the baseline b using corresponding values from the translation vectors t\n",
    "    ## baseline b is the euclidean norm of the difference vector (t1 - t2)\n",
    "    # b = np.linalg.norm(t_02-t_03)\n",
    "    ## z_obj = the depth estimated by the detection.\n",
    "    # depth = (b * focal_length) / disparity)\n",
    "    #stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "    #disparity = stereo.compute(imgL,imgR)\n",
    "    # disparity = x_left - x_right\n",
    "    \n",
    "    #(type, x_obj, y_obj, z_obj, height, width) = find_ball(frame)\n",
    "    \n",
    "    x_new = x\n",
    "    \n",
    "    z = np.array([[x_obj],[y_obj], [z_obj]])\n",
    "    Y, S, K, x_new, P = update(x, P, z, H, R)\n",
    "   \n",
    "    text1 = \"Position x= {}, y ={} z={}\".format(x_new[0], x_new[1], x_new[2])\n",
    "    text2 = \"Velocity x = {}, y = {}\".format(x_new[3], x_new[4], x_new[5])\n",
    "                                           \n",
    "    cv2.putText(frame, text1, (10, 50),  cv2.FONT_HERSHEY_DUPLEX, 0.4, (155, 0, 155), 1)\n",
    "    cv2.putText(frame, text2, (10, 70),  cv2.FONT_HERSHEY_DUPLEX, 0.4, (155, 0, 155), 1)\n",
    "   \n",
    "    #cv2.circle(frame, (int(x_new[0]), int(x_new[3])), int(max_radius),(0, 125, 255), 2)\n",
    "    ### Predict the next state\n",
    "    x, P = predict(x_new, P, F, u)\n",
    "    x_new = x\n",
    "    \n",
    "    #cv2.circle(frame, (int(x[0]), int(x[3])), int(max_radius),(0, 125, 255), 2)\n",
    "    \n",
    "    ### Draw the current tracked state and the predicted state on the image frame ###\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.waitKey(50)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5356592204823809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x1248 4 Pedestrians, 1 Car, 189.8ms\n",
      "Speed: 5.4ms preprocess, 189.8ms inference, 0.9ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 255\n",
      "509 236\n",
      "135 214\n",
      "430 250\n",
      "552 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 5 Pedestrians, 1 Car, 184.4ms\n",
      "Speed: 7.5ms preprocess, 184.4ms inference, 1.3ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 256\n",
      "134 228\n",
      "458 257\n",
      "521 235\n",
      "495 172\n",
      "552 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 2 Pedestrians, 1 Car, 154.6ms\n",
      "Speed: 8.2ms preprocess, 154.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 235\n",
      "460 254\n",
      "134 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 4 Pedestrians, 1 Car, 151.9ms\n",
      "Speed: 4.3ms preprocess, 151.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546 239\n",
      "475 254\n",
      "134 223\n",
      "533 240\n",
      "488 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 3 Pedestrians, 1 Car, 141.2ms\n",
      "Speed: 4.3ms preprocess, 141.2ms inference, 0.6ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 255\n",
      "560 240\n",
      "134 218\n",
      "531 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 5 Pedestrians, 1 Car, 156.9ms\n",
      "Speed: 8.1ms preprocess, 156.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504 255\n",
      "573 242\n",
      "531 164\n",
      "134 220\n",
      "534 163\n",
      "486 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 5 Pedestrians, 1 Car, 171.4ms\n",
      "Speed: 5.3ms preprocess, 171.4ms inference, 2.9ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 244\n",
      "508 255\n",
      "134 222\n",
      "589 243\n",
      "549 168\n",
      "531 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 6 Pedestrians, 1 Car, 165.3ms\n",
      "Speed: 5.8ms preprocess, 165.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 257\n",
      "597 244\n",
      "583 244\n",
      "134 219\n",
      "514 256\n",
      "500 172\n",
      "493 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 10 Pedestrians, 1 Car, 161.8ms\n",
      "Speed: 4.9ms preprocess, 161.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532 255\n",
      "601 244\n",
      "550 255\n",
      "500 172\n",
      "134 218\n",
      "504 173\n",
      "589 245\n",
      "613 242\n",
      "529 163\n",
      "509 172\n",
      "573 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x1248 8 Pedestrians, 1 Car, 147.1ms\n",
      "Speed: 5.6ms preprocess, 147.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1248, 1248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 256\n",
      "620 244\n",
      "134 220\n",
      "505 173\n",
      "525 166\n",
      "529 164\n",
      "607 247\n",
      "508 172\n",
      "541 252\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "images_left = sorted(glob.glob('final_project_2023_rect/seq_01/image_02/data/*.png'))\n",
    "images_right = sorted(glob.glob('final_project_2023_rect/seq_01/image_03/data/*.png'))\n",
    "assert images_left\n",
    "assert images_right\n",
    "\n",
    "focal_length = 956.9475\n",
    "b = np.linalg.norm(np.array([0.059896, -0.001367835, 0.004637624 ])-np.array([-0.4756270, 0.005296617, -0.005437198]))\n",
    "print(b)\n",
    "cv2.destroyAllWindows()\n",
    "classifier = Classifier(format='pt')\n",
    "for i in range(0, len(images_left)):\n",
    "    imgLeft = cv2.imread(images_left[i])\n",
    "    imgR = cv2.imread(images_right[i])\n",
    "    \n",
    "    imgL = cv2.cvtColor(imgLeft, cv2.COLOR_BGR2GRAY)\n",
    "    imgR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    results = classifier.predict(imgLeft)\n",
    "    \n",
    "    box = results[0].boxes[0].xywh\n",
    "    box1 = results[0].boxes[1].xywh\n",
    "    box = torch.squeeze(box)\n",
    "    for i in range(0,len(results[0])):\n",
    "        box = results[0].boxes[i].xywh\n",
    "        box = torch.squeeze(box)\n",
    "        print(int(box[0]), int(box[1]))\n",
    "        cv2.circle(imgLeft, (int(box[0]), int(box[1])), 3, (0, 0, 255), 5)\n",
    "    cv2.imshow('Testing image', imgLeft)\n",
    "        \n",
    "    #print(box)\n",
    "    \n",
    "    stereo = cv2.StereoBM_create(numDisparities=128, blockSize=15)\n",
    "    # min_disp = 3\n",
    "    # stereo.setMinDisparity(min_disp)\n",
    "    # stereo.setDisp12MaxDiff(100)\n",
    "    # stereo.setUniquenessRatio(50)\n",
    "    # stereo.setSpeckleRange(3)\n",
    "    # stereo.setSpeckleWindowSize(50)\n",
    "    disparity = stereo.compute(imgL,imgR)\n",
    "    norm_image = cv2.normalize(disparity, None, alpha = 0, beta = 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    dst = cv2.GaussianBlur(norm_image,(7,7),cv2.BORDER_DEFAULT)\n",
    "    #cv2.imshow('norm_image', dst)\n",
    "    cv2.waitKey(500)\n",
    "    \n",
    "    \n",
    "    depth = (b * focal_length) / disparity[240][448]\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4be9c908ebe39e7168c83d12fecab890f134a2bf8af6dfbceaf97ba05100539d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
