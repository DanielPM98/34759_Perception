{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06bbbf8b-095d-4e3f-a470-3d3599fafa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008db47b-17b8-448b-9f7c-752f3f4ce097",
   "metadata": {},
   "source": [
    "## CALIBRATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36adfbf5-81ae-4cf3-8aa7-5803a94aa452",
   "metadata": {},
   "source": [
    "The process of calibrating an image consists of mainly 3 steps: 1) find chessboard-corners in a dataset of images containing a chessboard. 2) Use the corner points to compute a camera matrix. 3) Use the camera matrix to undistort images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "533679dc-b28c-472c-9c07-275264e2ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration():\n",
    "    # termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 0.001)\n",
    "    \"\"\"\n",
    "    Implement the number of vertical and horizontal corners\n",
    "    nb_vertical = ...\n",
    "    nb_horizontal = ...\n",
    "    \"\"\"\n",
    "    nb_vertical = 5\n",
    "    nb_horizontal = 7\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((5*7,3), np.float32)\n",
    "    objp2 = np.zeros((5*7,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:5,0:7].T.reshape(-1,2)\n",
    "    objp2[:,:2] = np.mgrid[0:5,0:7].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints_left = [] # 2d points in image plane.\n",
    "    imgpoints_right = [] # 2d points in image plane.\n",
    "\n",
    "    images_left = sorted(glob.glob('raw_videos/calib/image_02/data/*.png'))\n",
    "    images_right = sorted(glob.glob('raw_videos/calib/image_03/data/*.png'))\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "    \n",
    "    for i in range(0,len(images_left)):\n",
    "        img_left= cv2.imread(images_left[i])\n",
    "        img_right = cv2.imread(images_right[i])\n",
    "        \n",
    "        gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # Detecting first chessboard\n",
    "        # Cropping an image\n",
    "        gray_left_cropped = gray_left[250:450, 800:1000]\n",
    "        gray_right_cropped = gray_right[250:450, 720:920]\n",
    "        \n",
    "        ret_left, corners_left = cv2.findChessboardCorners(gray_left_cropped, (nb_vertical,nb_horizontal), None)\n",
    "        ret_right, corners_right = cv2.findChessboardCorners(gray_right_cropped, (nb_vertical,nb_horizontal), None)\n",
    "        \n",
    "            \n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret_left == True and ret_right == True:\n",
    "            objpoints.append(objp)\n",
    "            \n",
    "            corners2_left = cv2.cornerSubPix(gray_left_cropped, corners_left, (7, 7), (-1, -1), criteria)\n",
    "            corners2_right = cv2.cornerSubPix(gray_right_cropped, corners_right, (7, 7), (-1, -1), criteria)\n",
    "            \n",
    "            for i in range(0,len(corners2_left)):\n",
    "                corners2_left[i][0][0] = corners2_left[i][0][0] + 800\n",
    "                corners2_left[i][0][1] = corners2_left[i][0][1] + 250\n",
    "                corners2_right[i][0][0] = corners2_right[i][0][0] + 720\n",
    "                corners2_right[i][0][1] = corners2_right[i][0][1] + 250\n",
    "               \n",
    "            imgpoints_left.append(corners2_left)\n",
    "            imgpoints_right.append(corners2_right)\n",
    "\n",
    "            # Draw the corners\n",
    "            img_left = cv2.drawChessboardCorners(img_left, (nb_vertical,nb_horizontal), corners2_left, ret_left)\n",
    "            img_right = cv2.drawChessboardCorners(img_right, (nb_vertical,nb_horizontal), corners2_right, ret_right)\n",
    "    \n",
    "        # Detecting the second chessboard   \n",
    "        gray_left_cropped = gray_left[50:250, 800:1000]\n",
    "        gray_right_cropped = gray_right[50:250, 700:900]\n",
    "        \n",
    "        ret_left, corners_left = cv2.findChessboardCorners(gray_left_cropped, (nb_vertical,nb_horizontal), None)\n",
    "        ret_right, corners_right = cv2.findChessboardCorners(gray_right_cropped, (nb_vertical,nb_horizontal), None)\n",
    "        \n",
    "         # If found, add object points, image points (after refining them)\n",
    "        if ret_left == True and ret_right == True:\n",
    "            objpoints.append(objp)\n",
    "            \n",
    "            corners2_left = cv2.cornerSubPix(gray_left_cropped, corners_left, (7, 7), (-1, -1), criteria)\n",
    "            corners2_right = cv2.cornerSubPix(gray_right_cropped, corners_right, (7, 7), (-1, -1), criteria)\n",
    "            \n",
    "            for i in range(0,len(corners2_left)):\n",
    "                corners2_left[i][0][0] = corners2_left[i][0][0] + 800\n",
    "                corners2_left[i][0][1] = corners2_left[i][0][1] + 50\n",
    "                corners2_right[i][0][0] = corners2_right[i][0][0] + 700\n",
    "                corners2_right[i][0][1] = corners2_right[i][0][1] + 50\n",
    "               \n",
    "            imgpoints_left.append(corners2_left)\n",
    "            imgpoints_right.append(corners2_right)\n",
    "\n",
    "            # Draw the corners\n",
    "            img_left = cv2.drawChessboardCorners(img_left, (nb_vertical,nb_horizontal), corners2_left, ret_left)\n",
    "            img_right = cv2.drawChessboardCorners(img_right, (nb_vertical,nb_horizontal), corners2_right, ret_right)\n",
    "        \n",
    "        # Detecting the third chessboard   \n",
    "        gray_left_cropped = gray_left[200:400, 1000:1250]\n",
    "        gray_right_cropped = gray_right[200:400, 900:1150]\n",
    "       # cv2.imshow('img',gray_right_cropped)\n",
    "        #cv2.waitKey(1000)\n",
    "        ret_left, corners_left = cv2.findChessboardCorners(gray_left_cropped, (nb_vertical,nb_horizontal), None)\n",
    "        ret_right, corners_right = cv2.findChessboardCorners(gray_right_cropped, (nb_vertical,nb_horizontal), None)\n",
    "        \n",
    "         # If found, add object points, image points (after refining them)\n",
    "        if ret_left == True and ret_right == True:\n",
    "            objpoints.append(objp)\n",
    "            \n",
    "            corners2_left = cv2.cornerSubPix(gray_left_cropped, corners_left, (7, 7), (-1, -1), criteria)\n",
    "            corners2_right = cv2.cornerSubPix(gray_right_cropped, corners_right, (7, 7), (-1, -1), criteria)\n",
    "            \n",
    "            for i in range(0,len(corners2_left)):\n",
    "                corners2_left[i][0][0] = corners2_left[i][0][0] + 1050\n",
    "                corners2_left[i][0][1] = corners2_left[i][0][1] + 200\n",
    "                corners2_right[i][0][0] = corners2_right[i][0][0] + 950\n",
    "                corners2_right[i][0][1] = corners2_right[i][0][1] + 200\n",
    "               \n",
    "            imgpoints_left.append(corners2_left)\n",
    "            imgpoints_right.append(corners2_right)\n",
    "\n",
    "            # Draw the corners\n",
    "            img_left = cv2.drawChessboardCorners(img_left, (nb_vertical,nb_horizontal), corners2_left, ret_left)\n",
    "            img_right = cv2.drawChessboardCorners(img_right, (nb_vertical,nb_horizontal), corners2_right, ret_right)\n",
    "            \n",
    "            \n",
    "        # Detecting the forth chessboard      \n",
    "        gray_left_cropped = gray_left[:, 0:400]\n",
    "        gray_right_cropped = gray_right[:, 0:400]\n",
    "        \n",
    "        ret_left, corners_left = cv2.findChessboardCorners(gray_left_cropped, (11,7), None)\n",
    "        ret_right, corners_right = cv2.findChessboardCorners(gray_right_cropped, (11,7), None)\n",
    "        \n",
    "         # If found, add object points, image points (after refining them)\n",
    "        if ret_left == True and ret_right == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2_left = cv2.cornerSubPix(gray_left_cropped, corners_left, (7, 7), (-1, -1), criteria)\n",
    "            corners2_right = cv2.cornerSubPix(gray_right_cropped, corners_right, (7, 7), (-1, -1), criteria)\n",
    "            \n",
    "            imgpoints_left.append(corners2_left[0:35])\n",
    "            imgpoints_right.append(corners2_right[0:35])\n",
    "            \n",
    "\n",
    "            img_left = cv2.drawChessboardCorners(img_left, (11,7), corners2_left, ret_left)\n",
    "            img_right = cv2.drawChessboardCorners(img_right, (11,7), corners2_right[0:35], ret_right)\n",
    "            \n",
    "            plot_image = np.concatenate((img_left, img_right), axis=1)\n",
    "            #plot_image = np.vstack((img_left, img_right))\n",
    "            cv2.imshow('img',plot_image)\n",
    "            cv2.waitKey(1000)\n",
    "        \n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    # Frame dimensions. Frames should be the same size.\n",
    "    w = img_left.shape[1]\n",
    "    h = img_left.shape[0]\n",
    "    print(w, h)\n",
    "    \n",
    "    # Get the camera matrix\n",
    "    ret, K_left, dist_left, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints_left, gray_left.shape[::-1], None, None) \n",
    "    ret, K_right, dist_right, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints_right, gray_right.shape[::-1], None, None)\n",
    "    \n",
    "    # Calibrate the stereo camera setup\n",
    "    stereocalibration_flags = cv2.CALIB_FIX_INTRINSIC\n",
    "    criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 50, 0.001)\n",
    "    \n",
    "    ret, CM_left, CM_dist_left, CM_right, CM_dist_right, R, T, E, F = cv2.stereoCalibrate(objpoints, imgpoints_left, imgpoints_right, K_left, dist_left,\n",
    "                                                                                    K_right, dist_right, (w, h), criteria = criteria_stereo, flags = stereocalibration_flags)\n",
    "\n",
    "    return CM_left, CM_right, CM_dist_left, CM_dist_right, R, T, F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b72e8f89-705a-4021-b7a8-5d646ba1e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392 512\n",
      "K_left:  [[420.79075487   0.         882.28498888]\n",
      " [  0.         458.82147516 266.02126249]\n",
      " [  0.           0.           1.        ]]\n",
      "Dist_left:  [[ 0.48369225  0.20845372 -0.13256534  0.03033536 -0.23010908]]\n",
      "K_right:  [[568.102483     0.         698.4106223 ]\n",
      " [  0.         643.03225644 261.24408749]\n",
      " [  0.           0.           1.        ]]\n",
      "Dist_right [[ 0.02230363 -0.00626007 -0.04006836 -0.00254069 -0.08591406]]\n",
      "R: [[ 0.38829627  0.70562936 -0.59271681]\n",
      " [ 0.23043464  0.54840441  0.8038361 ]\n",
      " [ 0.89225887 -0.44870904  0.05034194]]\n",
      "T:  [[ 31.46659704]\n",
      " [-30.93375973]\n",
      " [ 86.89060017]]\n",
      "F:  [[ 2.80673237e-06  1.82534495e-06 -1.19114693e-03]\n",
      " [-2.94859952e-07 -3.60205982e-06  2.38147321e-03]\n",
      " [-2.52815909e-03 -1.53395741e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "(K_left, K_right, dist_left, dist_right, R, T, F) = calibration()\n",
    "\n",
    "print(\"K_left: \",  K_left)\n",
    "print (\"Dist_left: \", dist_left)\n",
    "print(\"K_right: \",  K_right)\n",
    "print (\"Dist_right\", dist_right)\n",
    "print(\"R:\", R)\n",
    "print(\"T: \", T)\n",
    "print(\"F: \", F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e852866d-c518-4d77-ac6c-5bb865640500",
   "metadata": {},
   "source": [
    "## UNDISTORSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "157351cd",
   "metadata": {},
   "source": [
    "Using the extracted corners we can obtain a camera matrix that contains the information needed to undistort images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c758b350-56f0-4667-b96c-fae4e849f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(K_left, K_right, dist_left, dist_right):\n",
    "    images_left = sorted(glob.glob('raw_videos/calib/image_02/data/*.png'))\n",
    "    images_right = sorted(glob.glob('raw_videos/calib/image_03/data/*.png'))\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "    \n",
    "    path_out_left = 'raw_videos/calib/image_02/undistorted/left/left-'\n",
    "    path_out_right = 'raw_videos/calib/image_02/undistorted/right/right-'\n",
    "    print(path_out_left)\n",
    "    # Get optimal intrinsic matrix based on parameter alpha (used for rectification?)\n",
    "    '''if alpha>0, the undistorted result is likely to have some black pixels corresponding to \"virtual\" pixels outside of the captured distorted image'''\n",
    "    (h,w) = cv2.imread(images_left[0]).shape[0:2]\n",
    "    K_new_left, roi_left = cv2.getOptimalNewCameraMatrix(K_left, dist_left,(w,h), alpha=0)\n",
    "    K_new_right, roi_right = cv2.getOptimalNewCameraMatrix(K_right, dist_right,(w,h), alpha=0)\n",
    "    \n",
    "\n",
    "    for i in range(len(images_left)):\n",
    "        # Undistort\n",
    "        img_left= cv2.imread(images_left[i])\n",
    "        img_right = cv2.imread(images_right[i])\n",
    "        \n",
    "        dst_left = cv2.undistort(img_left, K_left, dist_left, None, K_new_left)\n",
    "        dst_right = cv2.undistort(img_right, K_right, dist_right, None, K_new_right)\n",
    "\n",
    "        # Crop the image\n",
    "        x, y, w, h = roi_left\n",
    "        dst_left = dst_left[y:y+h, x:x+w]\n",
    "        \n",
    "        x, y, w, h = roi_right\n",
    "        dst_right = dst_right[y:y+h, x:x+w]\n",
    "\n",
    "        # Save image\n",
    "        cv2.imwrite(path_out_left+str(i)+'.png', img_left)\n",
    "        cv2.imwrite(path_out_right+str(i)+'.png', dst_right)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea3f0a18-b832-4b55-ac20-a82ca2cf7150",
   "metadata": {},
   "source": [
    "## RECTIFICATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img1, img2, lines, pts1, pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    (r, c,_) = img1.shape\n",
    "    # r,c = img1.shape\n",
    "    # img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "    # img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        x0, y0 = map(int, [0, -r[2]/r[1]])\n",
    "        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n",
    "        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n",
    "        img1 = cv2.circle(img1, tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, tuple(pt2), 5, color, -1)\n",
    "    return img1, img2\n",
    "\n",
    "def draw_epipolar_lines(img_left, img_right):\n",
    "    '''Draws epipolar lines to the image'''\n",
    "    \n",
    "    # # Change to RGB\n",
    "    # gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "    # gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the keypoints and descriptors with SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp_left, des_left = sift.detectAndCompute(img_left, None)\n",
    "    kp_right, des_right = sift.detectAndCompute(img_right, None)\n",
    "\n",
    "    # Match points\n",
    "    matches = cv2.BFMatcher().match(des_left, des_right)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    nb_matches = 200  # Using 200 best matches\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp_left[m.queryIdx].pt)\n",
    "        pts2.append(kp_right[m.trainIdx].pt)\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    # Get fundamental matrix\n",
    "    F, inliers = cv2.findFundamentalMat(pts1, pts2, method=cv2.FM_RANSAC)\n",
    "\n",
    "    # Remove outliers\n",
    "    pts1 = pts1[inliers.ravel() == 1]\n",
    "    pts2 = pts2[inliers.ravel() == 1]\n",
    "\n",
    "    # Draw lines\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    epilines_left, keypoints_left = draw_lines(img_left, img_right, lines1, pts1, pts2)\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    epilines_right, keypoints_right = draw_lines(img_right, img_left, lines2, pts2, pts1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(10, 10))\n",
    "    axs[0].imshow(epilines_left)\n",
    "    axs[0].set_title('left epipolar lines')\n",
    "    axs[1].imshow(epilines_right)\n",
    "    axs[1].set_title('right epipolar lines')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8b085e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectification(CM_left, CM_dist_left, CM_right, CM_dist_right, R, T):\n",
    "     \n",
    "     images_left = sorted(glob.glob('raw_videos/calib/image_02/data/*.png'))\n",
    "     assert images_left\n",
    "     (h,w) = cv2.imread(images_left[0]).shape[0:2]\n",
    "     \n",
    "     R_left, R_right, P_left, P_right, Q, roi_left, roi_right= cv2.stereoRectify(CM_left, CM_dist_left, CM_right, CM_dist_right, (w,h), \n",
    "                                                    R, T, alpha=-1.0)\n",
    "     map1_x, map1_y = cv2.initUndistortRectifyMap(K_left, dist_left, R_left, P_left, (w, h), cv2.CV_32FC1)\n",
    "     map2_x, map2_y = cv2.initUndistortRectifyMap(K_right, dist_right, R_right, P_right, (w, h), cv2.CV_32FC1)\n",
    "    \n",
    "     return map1_x, map1_y, map2_x, map2_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(img_left, img_right, K_left, dist_left, K_right, dist_right, R, T, leftMapX, leftMapY,rightMapX, rightMapY, debug=False):\n",
    "    '''Rectify the image'''\n",
    "\n",
    "    left_rectified = np.zeros(img_left.shape[:2], np.uint8)\n",
    "    right_rectified = np.zeros(img_right.shape[:2], np.uint8)\n",
    "    left_rectified = cv2.remap(img_left, leftMapX, leftMapY, cv2.INTER_LINEAR, left_rectified, cv2.BORDER_CONSTANT)\n",
    "    right_rectified = cv2.remap(img_right, rightMapX, rightMapY, cv2.INTER_LINEAR, right_rectified, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    if debug:\n",
    "        draw_epipolar_lines(left_rectified,right_rectified)\n",
    "\n",
    "    return left_rectified, right_rectified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9458b5d3-6ab2-4264-89a9-14645e797351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rectify_uncalibrated(img_left, img_right, debug=False):  \n",
    "    ''' We use the fundamental matrix from calibration.'''\n",
    "    \n",
    "    # Find the keypoints and descriptors with SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp_left, des_left = sift.detectAndCompute(img_left, None)\n",
    "    kp_right, des_right = sift.detectAndCompute(img_right, None)\n",
    "    [F, mask] = cv2.findFundamentalMat(kp_left, kp_right, 'Method','Ransac');\n",
    "    # Match points\n",
    "    matches = cv2.BFMatcher().match(des_left, des_right)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    nb_matches = 200  # Using 200 best matches\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp_left[m.queryIdx].pt)\n",
    "        pts2.append(kp_right[m.trainIdx].pt)\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "    \n",
    "    # Rectify images\n",
    "    (h,w,_) = img_left.shape\n",
    "    _, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(pts1), np.float32(pts2), F, (w,h))\n",
    "    left_rectified = cv2.warpPerspective(img_left, H1, (w,h))\n",
    "    right_rectified = cv2.warpPerspective(img_right, H2, (w,h))\n",
    "\n",
    "    if debug:\n",
    "        draw_epipolar_lines(left_rectified,right_rectified)\n",
    "\n",
    "    return left_rectified,right_rectified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6d49499-f842-4c41-9efb-ba7224cff9c2",
   "metadata": {},
   "source": [
    "The last step is to check the results on an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a4b0ed2-725a-4580-91db-ff50ec966e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated = True\n",
    "if calibrated:\n",
    "    images_left = sorted(glob.glob('raw_videos/calib/image_02/data/*.png'))\n",
    "    images_right = sorted(glob.glob('raw_videos/calib/image_03/data/*.png'))\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "else:\n",
    "    undistort(K_left, K_right, dist_left, dist_right)\n",
    "    images_left = sorted(glob.glob('raw_videos/calib/image_02/undistorted/left/*.png'))\n",
    "    images_right = sorted(glob.glob('raw_videos/calib/image_02/undistorted/right/*.png'))\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "\n",
    "for i in range(0,len(images_left)):\n",
    "    img_left= cv2.imread(images_left[i])\n",
    "    img_right = cv2.imread(images_right[i])\n",
    "\n",
    "    if calibrated:\n",
    "        map1_x, map1_y, map2_x, map2_y = rectification(K_left, dist_left, K_right, dist_right, R, T)\n",
    "        left_rectified,right_rectified = remap(img_left, img_right, K_left, dist_left, K_right, dist_right, R, T, map1_x, map1_y,map2_x, map2_y, debug=True)\n",
    "    else:\n",
    "        left_rectified,right_rectified = rectify_uncalibrated(img_left, img_right, debug=False)\n",
    "\n",
    "    cv2.imshow('img',left_rectified)\n",
    "    cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "4be9c908ebe39e7168c83d12fecab890f134a2bf8af6dfbceaf97ba05100539d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
